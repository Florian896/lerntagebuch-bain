---

title: "Linked Data"  
date: 2023-05-30   

---


Liebes Tagebuch

Nach den generellen Informationen zur Vorlesungsrückmeldung und der Prüfungsleistung haben wir die neuen künstlichen Intelligenzen angeschaut.
Nämlich ChatGPT und Bing.
Ja, es scheint tatsächlich so als könnte Winzigweich es doch noch schaffen Bing doch noch zu etwas relevantem zu machen.
Wir haben den beiden verschiedene Fragen gestellt um ihnen auf den (digitalen) Zahn zu fühlen.

Bing hat weniger Antworten gefunden und das jeweils auch ganz offen zugegeben, was mir immens sympathisch ist.
Wie Wahrheitshaltig seine Antworten, die es findet, sind, konnte ich noch nicht in Erfahrung bringen.

Ich habe mehr Erfahrung mit ChatGPT.
Die Antworten, die wir davon erhielten waren ziemlich gut und durchgehend sehr schön formuliert.
Das grosse Problem ist, dass Fakten sowie ~~Lügen~~ Falschmeldungen ausgegeben werden.
Insbesondere die Frage ``Welche Archivinformationssysteme beherschen den Records in Contexts Standard?`` zeigt das Problem auf.
Wir fanden drei Fehler in der Antwort.
Diese Fehler waren von Fakten umgeben und waren realistisch genug um von Uninformierten geglaubt zu werden.
Auf die meisten Fragen erhielten wir jedoch keine Fehler, bliben aber auf einem recht oberflächlichen Level.
Was uns auch auffiel, war, dass bei einer Antwort sogar zwei unserer Lerntagebücher als Quellen angegeben wurden.
Es liege mir fern anzudeuten unsere Lerntagebücher seien nicht von höchster Qualität, aber ich komme dennoch nicht umhin mich zu wundern woher die künstlichen Intelligenzen das wissen, da unsere Lerntagebücher (noch) keiner formeller Prüfung unterzogen wurden.
Weiter werden bei rein grammatikalischen umformungen der Frage komplett andere Antworten generiert.

Folglich sind diese Werkzeuge zwar sehr interessant und kurzweilig, aber von Verlässlichkeit noch weit entfernt.
Gewisse Aufgaben können sie erfüllen, die Resultate müssen aber unbedingt von ihnen unabhängig validiert werden.

Im Jahre 2012 wurde BIBFRAME als Nachfolger von MARC21 entwickelt.
Inzwischen gibt es BIBFRAME 2.0.
Es besteht aus einem Modell und einem Vokabular.
Die meiner Meinung nach beste Erklärung ist das folgende Bild:

![BIBFRAME Model](https://www.loc.gov/bibframe/docs/images/bf2-model.jpg)

Unser [gemeinsames Dokument](https://pad.gwdg.de/_6j1KL1wS9O7PD09pYDGoA?view#BIBFRAME) erklärt "[BIBFRAME] basiert auf Functional Requirements for Bibliographic Records (FRBR) sowie Resource Description and Access (RDA) als Regelwerk, setzt diese aber nicht vollständig um".
Es ist durchaus angenehmer zu lesen als MARC21, aber immernoch ein XML mit all den anstrengenden "Tags" die <geöffnet> und wieder <\geschlossen> werden.
Meiner meinung müsste eine alternative Darstellung mit weniger technischem Text möglich sein.
Phython schafft das schliesslich auch.

> As a bibliographic description format, the MARC format focuses on catalog records that are independently understandable. MARC aggregates information about the conceptual work and its physical carrier and uses strings for identifiers such as personal names, corporate name, subjects, etc. that have value outside the record itself.

> Instead of bundling everything neatly as a “record” and potentially duplicating information across multiple records, the BIBFRAME Model relies heavily on relationships between resources (Work-to-Work relationships; Work-to-Instance relationships; Work-to-Agent relationships). It manages this by using controlled identifiers for things (people, places, languages, etc).

[Library of Congress](https://www.loc.gov/bibframe/faqs/#q04)

Zum Abschluss haben wir noch mit Open Refine und Wikidata Datensätze erweitert.
Wenn die einzelnen Einträge eindeutig definiert sind, zB mit GND ID, können von verschiedenen Quellen dazugehörige Daten angefügt werden.
Diese Quellen können Wikidata, GND, sogar Bahama Leaks oder andere sein.
Es lässt sich relativ einfach bedienen und die Daten aus Wikidata dürfen weiterverwendet werden.
Sogar die Bilder!
Open Refine ist wirklich eine wunderbare Sache.

Liebe Grüsse

Florian
